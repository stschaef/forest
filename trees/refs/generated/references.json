[
  {
    "DOI": "10.1007/BFb0022257",
    "ISBN": "978-3-540-49404-1",
    "abstract": "We define matchings, and show that they capture the essence of context-freeness. More precisely, we show that the class of context-free languages coincides with the class of those sets of strings which can be defined by sentences of the form ∃ bϕ, where ϕ is first order, b is a binary predicate symbol, and the range of the second order quantifier is restricted to the class of matchings. Several variations and extensions are discussed.",
    "author": [
      {
        "family": "Lautemann",
        "given": "Clemens"
      },
      {
        "family": "Schwentick",
        "given": "Thomas"
      },
      {
        "family": "Thérien",
        "given": "Denis"
      }
    ],
    "collection-title": "Lecture Notes in Computer Science",
    "container-title": "Computer Science Logic",
    "editor": [
      {
        "family": "Pacholski",
        "given": "Leszek"
      },
      {
        "family": "Tiuryn",
        "given": "Jerzy"
      }
    ],
    "id": "lautemann_logics_1995",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "page": "205-216",
    "publisher": "Springer",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Logics for context-free languages",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1925844.1926429",
    "ISSN": "0362-1340",
    "URL": "https://dl.acm.org/doi/10.1145/1925844.1926429",
    "abstract": "We present a new sound and complete axiomatization of regular expression containment. It consists of the conventional axiomatization of concatenation, alternation, empty set and (the singleton set containing) the empty string as an idempotent semiring, the fixed- point rule E* = 1 + E × E* for Kleene-star, and a general coinduction rule as the only additional rule. Our axiomatization gives rise to a natural computational interpretation of regular expressions as simple types that represent parse trees, and of containment proofs as coercions. This gives the axiom- atization a Curry-Howard-style constructive interpretation: Containment proofs do not only certify a language-theoretic contain- ment, but, under our computational interpretation, constructively transform a membership proof of a string in one regular expression into a membership proof of the same string in another regular expression. We show how to encode regular expression equivalence proofs in Salomaa’s, Kozen’s and Grabmayer’s axiomatizations into our containment system, which equips their axiomatizations with a computational interpretation and implies completeness of our axiomatization. To ensure its soundness, we require that the computational interpretation of the coinduction rule be a hereditarily total function. Hereditary totality can be considered the mother of syn- tactic side conditions: it \"explains\" their soundness, yet cannot be used as a conventional side condition in its own right since it turns out to be undecidable. We discuss application of regular expressions as types to bit coding of strings and hint at other applications to the wide-spread use of regular expressions for substring matching, where classical automata-theoretic techniques are a priori inapplicable. Neither regular expressions as types nor subtyping interpreted coercively are novel per se. Somewhat surprisingly, this seems to be the first investigation of a general proof-theoretic framework for the latter in the context of the former, however.",
    "accessed": {
      "date-parts": [
        [
          2023,
          11,
          28
        ]
      ]
    },
    "author": [
      {
        "family": "Henglein",
        "given": "Fritz"
      },
      {
        "family": "Nielsen",
        "given": "Lasse"
      }
    ],
    "container-title": "ACM SIGPLAN Notices",
    "id": "henglein_regular_2011",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2011,
          1
        ]
      ]
    },
    "keyword": "axiomatization, coercion, coinduction, computational interpretation, containment, equivalence, regular expression, type",
    "page": "385-398",
    "title": "Regular expression containment: Coinductive axiomatization and computational interpretation",
    "title-short": "Regular expression containment",
    "type": "article-journal",
    "volume": "46"
  },
  {
    "DOI": "10.4204/EPTCS.126.4",
    "ISSN": "2075-2180",
    "URL": "http://arxiv.org/abs/1309.0893",
    "abstract": "We give a natural complete infinitary axiomatization of the equational theory of the context-free languages, answering a question of Lei{\\ss} (1992).",
    "accessed": {
      "date-parts": [
        [
          2023,
          11,
          28
        ]
      ]
    },
    "author": [
      {
        "family": "Grathwohl",
        "given": "Niels Bjørn Bugge"
      },
      {
        "family": "Henglein",
        "given": "Fritz"
      },
      {
        "family": "Kozen",
        "given": "Dexter"
      }
    ],
    "container-title": "Electronic Proceedings in Theoretical Computer Science",
    "id": "grathwohl_infinitary_2013",
    "issued": {
      "date-parts": [
        [
          2013,
          8
        ]
      ]
    },
    "keyword": "Computer Science - Formal Languages and Automata Theory, Computer Science - Logic in Computer Science",
    "note": "arXiv:1309.0893 [cs]",
    "page": "44-55",
    "title": "Infinitary Axiomatization of the Equational Theory of Context-Free Languages",
    "type": "article-journal",
    "volume": "126"
  },
  {
    "DOI": "10.1145/2676726.2676969",
    "ISBN": "978-1-4503-3300-9",
    "URL": "https://dl.acm.org/doi/10.1145/2676726.2676969",
    "abstract": "In this paper, we show how to integrate linear types with type dependency, by extending the linear/non-linear calculus of Benton to support type dependency.",
    "accessed": {
      "date-parts": [
        [
          2024,
          1,
          4
        ]
      ]
    },
    "author": [
      {
        "family": "Krishnaswami",
        "given": "Neelakantan R."
      },
      {
        "family": "Pradic",
        "given": "Pierre"
      },
      {
        "family": "Benton",
        "given": "Nick"
      }
    ],
    "container-title": "Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "id": "krishnaswami_integrating_2015",
    "issued": {
      "date-parts": [
        [
          2015,
          1
        ]
      ]
    },
    "page": "17-30",
    "publisher": "ACM",
    "publisher-place": "Mumbai India",
    "title": "Integrating Linear and Dependent Types",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/S0304-3975(01)00241-9",
    "ISSN": "03043975",
    "URL": "https://linkinghub.elsevier.com/retrieve/pii/S0304397501002419",
    "abstract": "We present the general theory of the method of glueing and associated technique of orthogonality for constructing categorical models of all the structure of linear logic: in particular we treat the exponentials in detail. We indicate simple applications of the methods and show that they cover familiar examples. c 2002 Elsevier Science B.V. All rights reserved.",
    "accessed": {
      "date-parts": [
        [
          2024,
          3,
          4
        ]
      ]
    },
    "author": [
      {
        "family": "Hyland",
        "given": "Martin"
      },
      {
        "family": "Schalk",
        "given": "Andrea"
      }
    ],
    "container-title": "Theoretical Computer Science",
    "id": "hyland_glueing_2003",
    "issue": "1-2",
    "issued": {
      "date-parts": [
        [
          2003,
          2
        ]
      ]
    },
    "page": "183-231",
    "title": "Glueing and orthogonality for models of linear logic",
    "type": "article-journal",
    "volume": "294"
  },
  {
    "DOI": "10.1145/3314221.3314625",
    "ISBN": "978-1-4503-6712-7",
    "URL": "https://dl.acm.org/doi/10.1145/3314221.3314625",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          22
        ]
      ]
    },
    "author": [
      {
        "family": "Krishnaswami",
        "given": "Neelakantan R."
      },
      {
        "family": "Yallop",
        "given": "Jeremy"
      }
    ],
    "container-title": "Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "id": "krishnaswami_typed_2019",
    "issued": {
      "date-parts": [
        [
          2019,
          6
        ]
      ]
    },
    "page": "379-393",
    "publisher": "ACM",
    "publisher-place": "Phoenix AZ USA",
    "title": "A typed, algebraic approach to parsing",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1538788.1538814",
    "ISSN": "0001-0782, 1557-7317",
    "URL": "https://dl.acm.org/doi/10.1145/1538788.1538814",
    "abstract": "This paper reports on the development and formal verification (proof of semantic preservation) of CompCert, a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          22
        ]
      ]
    },
    "author": [
      {
        "family": "Leroy",
        "given": "Xavier"
      }
    ],
    "container-title": "Communications of the ACM",
    "id": "leroy_formal_2009",
    "issue": "7",
    "issued": {
      "date-parts": [
        [
          2009,
          7
        ]
      ]
    },
    "page": "107-115",
    "title": "Formal verification of a realistic compiler",
    "type": "article-journal",
    "volume": "52"
  },
  {
    "DOI": "10.1145/2535838.2535841",
    "ISBN": "978-1-4503-2544-8",
    "URL": "https://dl.acm.org/doi/10.1145/2535838.2535841",
    "abstract": "We have developed and mechanically veriﬁed an ML system called CakeML, which supports a substantial subset of Standard ML. CakeML is implemented as an interactive read-eval-print loop (REPL) in x86-64 machine code. Our correctness theorem ensures that this REPL implementation prints only those results permitted by the semantics of CakeML. Our veriﬁcation effort touches on a breadth of topics including lexing, parsing, type checking, incremental and dynamic compilation, garbage collection, arbitraryprecision arithmetic, and compiler bootstrapping.",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          22
        ]
      ]
    },
    "author": [
      {
        "family": "Kumar",
        "given": "Ramana"
      },
      {
        "family": "Myreen",
        "given": "Magnus O."
      },
      {
        "family": "Norrish",
        "given": "Michael"
      },
      {
        "family": "Owens",
        "given": "Scott"
      }
    ],
    "container-title": "Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "id": "kumar_cakeml_2014",
    "issued": {
      "date-parts": [
        [
          2014,
          1
        ]
      ]
    },
    "page": "179-191",
    "publisher": "ACM",
    "publisher-place": "San Diego California USA",
    "title": "CakeML: A verified implementation of ML",
    "title-short": "CakeML",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1993316.1993532",
    "abstract": "Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to ﬁnd compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our ﬁrst contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undeﬁned and unspeciﬁed behaviors that would destroy its ability to automatically ﬁnd wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.",
    "author": [
      {
        "family": "Yang",
        "given": "Xuejun"
      },
      {
        "family": "Chen",
        "given": "Yang"
      },
      {
        "family": "Eide",
        "given": "Eric"
      },
      {
        "family": "Regehr",
        "given": "John"
      }
    ],
    "id": "yangFindingUnderstandingBugs",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "title": "Finding and Understanding Bugs in C Compilers",
    "type": "article-journal"
  },
  {
    "DOI": "10.1007/978-3-642-28869-2_20",
    "ISBN": "978-3-642-28868-5 978-3-642-28869-2",
    "URL": "http://link.springer.com/10.1007/978-3-642-28869-2_20",
    "abstract": "An LR(1) parser is a ﬁnite-state automaton, equipped with a stack, which uses a combination of its current state and one lookahead symbol in order to determine which action to perform next. We present a validator which, when applied to a context-free grammar G and an automaton A, checks that A and G agree. Validating the parser provides the correctness guarantees required by veriﬁed compilers and other high-assurance software that involves parsing. The validation process is independent of which technique was used to construct A. The validator is implemented and proved correct using the Coq proof assistant. As an application, we build a formally-veriﬁed parser for the C99 language.",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          22
        ]
      ]
    },
    "author": [
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Pottier",
        "given": "François"
      },
      {
        "family": "Leroy",
        "given": "Xavier"
      }
    ],
    "container-title": "Programming Languages and Systems",
    "editor": [
      {
        "family": "Hutchison",
        "given": "David"
      },
      {
        "family": "Kanade",
        "given": "Takeo"
      },
      {
        "family": "Kittler",
        "given": "Josef"
      },
      {
        "family": "Kleinberg",
        "given": "Jon M."
      },
      {
        "family": "Mattern",
        "given": "Friedemann"
      },
      {
        "family": "Mitchell",
        "given": "John C."
      },
      {
        "family": "Naor",
        "given": "Moni"
      },
      {
        "family": "Nierstrasz",
        "given": "Oscar"
      },
      {
        "family": "Pandu Rangan",
        "given": "C."
      },
      {
        "family": "Steffen",
        "given": "Bernhard"
      },
      {
        "family": "Sudan",
        "given": "Madhu"
      },
      {
        "family": "Terzopoulos",
        "given": "Demetri"
      },
      {
        "family": "Tygar",
        "given": "Doug"
      },
      {
        "family": "Vardi",
        "given": "Moshe Y."
      },
      {
        "family": "Weikum",
        "given": "Gerhard"
      },
      {
        "family": "Seidl",
        "given": "Helmut"
      }
    ],
    "id": "jourdanValidatingLRParsers2012",
    "issued": {
      "date-parts": [
        [
          2012
        ]
      ]
    },
    "note": "Series Title: Lecture Notes in Computer Science",
    "page": "397-416",
    "publisher": "Springer Berlin Heidelberg",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Validating LR(1) Parsers",
    "type": "chapter",
    "volume": "7211"
  },
  {
    "DOI": "10.1007/BFb0022251",
    "ISBN": "978-3-540-60017-6 978-3-540-49404-1",
    "URL": "http://link.springer.com/10.1007/BFb0022251",
    "abstract": "Intuitionistic linear logic regains the expressive power of intuitionistic logic through the ! (’of course’) modality. Benton, Bierman, Hyland and de Paiva have given a term assignment system for ILL and an associated notion of categorical model in which the ! modality is modelled by a comonad satisfying certain extra conditions. Ordinary intuitionistic logic is then modelled in a cartesian dosed category which arises as a full subcategory of the category of coalgebras for the comonad. This paper attempts to explain the connection between ILL and IL more directly and symmetricallyby giving a logic, term calculus and categorical model for a system in which the linear and non-linear worlds exist on an equal footing, with operations allowing one to pass in both directions. We start from the categorical model of ILL given by Benton, Bierman, Hyland and de Paiva and show that this is equivalent to having a symmetric monoidal adjunction between a symmetric monoidal dosed category and a cartesian closed category. We then derive both a sequent calculus and a natural deduction presentation of the logic corresponding to the new notion of model.",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          27
        ]
      ]
    },
    "author": [
      {
        "family": "Benton",
        "given": "P. N."
      }
    ],
    "container-title": "Computer Science Logic",
    "editor": [
      {
        "family": "Goos",
        "given": "Gerhard"
      },
      {
        "family": "Hartmanis",
        "given": "Juris"
      },
      {
        "family": "Van Leeuwen",
        "given": "Jan"
      },
      {
        "family": "Pacholski",
        "given": "Leszek"
      },
      {
        "family": "Tiuryn",
        "given": "Jerzy"
      }
    ],
    "id": "bentonMixedLinearNonlinear1995",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "note": "Series Title: Lecture Notes in Computer Science",
    "page": "121-135",
    "publisher": "Springer Berlin Heidelberg",
    "publisher-place": "Berlin, Heidelberg",
    "title": "A mixed linear and non-linear logic: Proofs, terms and models: Extended abstract",
    "title-short": "A mixed linear and non-linear logic",
    "type": "chapter",
    "volume": "933"
  },
  {
    "DOI": "10.1145/321239.321249",
    "ISSN": "0004-5411, 1557-735X",
    "URL": "https://dl.acm.org/doi/10.1145/321239.321249",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          29
        ]
      ]
    },
    "author": [
      {
        "family": "Brzozowski",
        "given": "Janusz A."
      }
    ],
    "container-title": "Journal of the ACM",
    "id": "brzozowskiDerivativesRegularExpressions1964",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1964,
          10
        ]
      ]
    },
    "page": "481-494",
    "title": "Derivatives of Regular Expressions",
    "type": "article-journal",
    "volume": "11"
  },
  {
    "DOI": "10.1145/2034773.2034801",
    "ISBN": "978-1-4503-0865-6",
    "URL": "https://dl.acm.org/doi/10.1145/2034773.2034801",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          29
        ]
      ]
    },
    "author": [
      {
        "family": "Might",
        "given": "Matthew"
      },
      {
        "family": "Darais",
        "given": "David"
      },
      {
        "family": "Spiewak",
        "given": "Daniel"
      }
    ],
    "container-title": "Proceedings of the 16th ACM SIGPLAN international conference on Functional programming",
    "id": "mightParsingDerivativesFunctional2011",
    "issued": {
      "date-parts": [
        [
          2011,
          9
        ]
      ]
    },
    "page": "189-195",
    "publisher": "ACM",
    "publisher-place": "Tokyo Japan",
    "title": "Parsing with derivatives: A functional pearl",
    "title-short": "Parsing with derivatives",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1147/rd.32.0114",
    "ISSN": "0018-8646, 0018-8646",
    "URL": "http://ieeexplore.ieee.org/document/5392601/",
    "abstract": "Finite automata are considered in this paper as instruments for classifying finite tapes. Each onetape automaton defines a set of tapes, a two-tape automaton defines a set of pairs of tapes, et cetera. The structure of the defined sets is studied. Various generalizations of the notion of an automaton are introduced and their relation to the classical automata is determined. Some decision problems concerning automata are shown to be solvable by effective algorithms; others turn out to be unsolvable by algorithms.",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          29
        ]
      ]
    },
    "author": [
      {
        "family": "Rabin",
        "given": "M. O."
      },
      {
        "family": "Scott",
        "given": "D."
      }
    ],
    "container-title": "IBM Journal of Research and Development",
    "id": "rabinFiniteAutomataTheir1959",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          1959,
          4
        ]
      ]
    },
    "page": "114-125",
    "title": "Finite Automata and Their Decision Problems",
    "type": "article-journal",
    "volume": "3"
  },
  {
    "DOI": "10.1017/S0956796808007090",
    "ISSN": "0956-7968, 1469-7653",
    "URL": "https://www.cambridge.org/core/product/identifier/S0956796808007090/type/journal_article",
    "abstract": "Abstract Regular-expression derivatives are an old, but elegant, technique for compiling regular expressions to deterministic finite-state machines. It easily supports extending the regular-expression operators with boolean operations, such as intersection and complement. Unfortunately, this technique has been lost in the sands of time and few computer scientists are aware of it. In this paper, we reexamine regular-expression derivatives and report on our experiences in the context of two different functional-language implementations. The basic implementation is simple and we show how to extend it to handle large character sets (e.g., Unicode). We also show that the derivatives approach leads to smaller state machines than the traditional algorithm given by McNaughton and Yamada.",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          29
        ]
      ]
    },
    "author": [
      {
        "family": "Owens",
        "given": "Scott"
      },
      {
        "family": "Reppy",
        "given": "John"
      },
      {
        "family": "Turon",
        "given": "Aaron"
      }
    ],
    "container-title": "Journal of Functional Programming",
    "id": "owensRegularexpressionDerivativesReexamined2009",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2009,
          3
        ]
      ]
    },
    "page": "173-190",
    "title": "Regular-expression derivatives re-examined",
    "type": "article-journal",
    "volume": "19"
  },
  {
    "DOI": "10.1145/363347.363387",
    "ISSN": "0001-0782, 1557-7317",
    "URL": "https://dl.acm.org/doi/10.1145/363347.363387",
    "abstract": "A method for locating specific character strings embedded in character text is described and an implementation of this method in the form of a compiler is discussed. The compiler accepts a regular expression as source language and produces an IBM 7094 program as object language. The object program then accepts the text to be searched as input and produces a signal every time an embedded string in the text matches the given regular expression. Examples, problems, and solutions are also presented.",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          29
        ]
      ]
    },
    "author": [
      {
        "family": "Thompson",
        "given": "Ken"
      }
    ],
    "container-title": "Communications of the ACM",
    "id": "thompsonProgrammingTechniquesRegular1968",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          1968,
          6
        ]
      ]
    },
    "page": "419-422",
    "title": "Programming Techniques: Regular expression search algorithm",
    "title-short": "Programming Techniques",
    "type": "article-journal",
    "volume": "11"
  },
  {
    "DOI": "10.1007/BFb0048939",
    "ISBN": "978-3-540-38933-0",
    "URL": "https://doi.org/10.1007/BFb0048939",
    "abstract": "We study the class of operations definable from the given operations of an algebra of sets by union, composition, and fixed points; we obtain two theorems on definable operations that give us as special case the regular-equals-recognisable theorem of generalised finite automata theory. Definable operations arise also as the operations computable by charts; by translating into predicate logic, we obtain Manna’s formulas for termination and correctness of flowcharts.",
    "author": [
      {
        "family": "Bekić",
        "given": "Hans"
      }
    ],
    "container-title": "Programming languages and their definition: H. Bekič (1936–1982)",
    "editor": [
      {
        "family": "Jones",
        "given": "C. B."
      }
    ],
    "id": "Bekić1984",
    "issued": {
      "date-parts": [
        [
          1984
        ]
      ]
    },
    "page": "30-55",
    "publisher": "Springer Berlin Heidelberg",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Definable operations in general algebras, and the theory of automata and flowcharts",
    "type": "chapter"
  },
  {
    "DOI": "10.1145/3591264",
    "ISSN": "2475-1421",
    "URL": "https://dl.acm.org/doi/10.1145/3591264",
    "abstract": "File formats specify how data is encoded for persistent storage. They cannot be formalized as context-free grammars since their specifications include context-sensitive patterns such as the random access pattern and the type-length-value pattern. We propose a new grammar mechanism called Interval Parsing Grammars IPGs) for file format specifications. An IPG attaches to every nonterminal/terminal an interval, which specifies the range of input the nonterminal/terminal consumes. By connecting intervals and attributes, the context-sensitive patterns in file formats can be well handled. In this paper, we formalize IPGs’ syntax as well as its semantics, and its semantics naturally leads to a parser generator that generates a recursive-descent parser from an IPG. In general, IPGs are declarative, modular, and enable termination checking. We have used IPGs to specify a number of file formats including ZIP, ELF, GIF, PE, and part of PDF; we have also evaluated the performance of the generated parsers.",
    "accessed": {
      "date-parts": [
        [
          2024,
          4,
          29
        ]
      ]
    },
    "author": [
      {
        "family": "Zhang",
        "given": "Jialun"
      },
      {
        "family": "Morrisett",
        "given": "Greg"
      },
      {
        "family": "Tan",
        "given": "Gang"
      }
    ],
    "container-title": "Proceedings of the ACM on Programming Languages",
    "id": "zhangIntervalParsingGrammars2023",
    "issue": "PLDI",
    "issued": {
      "date-parts": [
        [
          2023,
          6
        ]
      ]
    },
    "page": "1073-1095",
    "title": "Interval Parsing Grammars for File Format Parsing",
    "type": "article-journal",
    "volume": "7"
  },
  {
    "author": [
      {
        "family": "Chomsky",
        "given": "Noam"
      }
    ],
    "container-title": "Handbook of Mathematical Psychology",
    "id": "chom1963",
    "issued": {
      "date-parts": [
        [
          1963
        ]
      ]
    },
    "page": "323-418",
    "title": "Formal properties of grammars",
    "type": "article-journal",
    "volume": "II"
  },
  {
    "DOI": "10.1109/TIT.1956.1056813",
    "author": [
      {
        "family": "Chomsky",
        "given": "N."
      }
    ],
    "container-title": "IRE Transactions on Information Theory",
    "id": "chomThreeModels1956",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          1956
        ]
      ]
    },
    "keyword": "Natural languages;Testing;Laboratories;Markov processes;Impedance matching;Kernel;Research and development",
    "page": "113-124",
    "title": "Three models for the description of language",
    "type": "article-journal",
    "volume": "2"
  },
  {
    "DOI": "https://doi.org/10.1016/S0019-9958(65)90426-2",
    "ISSN": "0019-9958",
    "URL": "https://www.sciencedirect.com/science/article/pii/S0019995865904262",
    "abstract": "There has been much recent interest in languages whose grammar is sufficiently simple that an efficient left-to-right parsing algorithm can be mechanically produced from the grammar. In this paper, we define LR(k) grammars, which are perhaps the most general ones of this type, and they provide the basis for understanding all of the special tricks which have been used in the construction of parsing algorithms for languages with simple structure, e.g. algebraic languages. We give algorithms for deciding if a given grammar satisfies the LR(k) condition, for given k, and also give methods for generating recognizes for LR(k) grammars. It is shown that the problem of whether or not a grammar is LR(k) for some k is undecidable, and the paper concludes by establishing various connections between LR(k) grammars and deterministic languages. In particular, the LR(k) condition is a natural analogue, for grammars, of the deterministic condition, for languages.",
    "author": [
      {
        "family": "Knuth",
        "given": "Donald E."
      }
    ],
    "container-title": "Information and Control",
    "id": "KNUTH1965607",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          1965
        ]
      ]
    },
    "page": "607-639",
    "title": "On the translation of languages from left to right",
    "type": "article-journal",
    "volume": "8"
  },
  {
    "DOI": "10.1145/362007.362035",
    "ISSN": "0001-0782",
    "URL": "https://doi.org/10.1145/362007.362035",
    "abstract": "A parsing algorithm which seems to be the most efficient general context-free algorithm known is described. It is similar to both Knuth’s LR(k) algorithm and the familiar top-down algorithm. It has a time bound proportional to n3 (where n is the length of the string being parsed) in general; it has an n2 bound for unambiguous grammars; and it runs in linear time on a large class of grammars, which seems to include most practical context-free programming language grammars. In an empirical comparison it appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick.",
    "author": [
      {
        "family": "Earley",
        "given": "Jay"
      }
    ],
    "container-title": "Commun. ACM",
    "id": "Earley1970",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          1970,
          2
        ]
      ]
    },
    "keyword": "compilers, computational complexity, context-free grammar, parsing, syntax analysis",
    "page": "94-102",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An efficient context-free parsing algorithm",
    "type": "article-journal",
    "volume": "13"
  },
  {
    "author": [
      {
        "family": "Johnson",
        "given": "Stephen C."
      }
    ],
    "id": "Johnsonyacc",
    "issued": {
      "date-parts": [
        [
          1975
        ]
      ]
    },
    "page": "PS1:15-1 - PS1:15-32",
    "publisher": "AT&T Bell Laboratories",
    "publisher-place": "Murray Hill, New Jersey 07974",
    "title": "Yacc: Yet another compiler-compiler",
    "title-short": "Yacc",
    "type": "report"
  },
  {
    "author": [
      {
        "family": "Kozen",
        "given": "Dexter"
      }
    ],
    "container-title": "ACM Transactions on Programming Languages and Systems (TOPLAS)",
    "id": "kozen1997kleene",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "title": "Kleene algebra with tests",
    "type": "article-journal"
  },
  {
    "author": [
      {
        "family": "Angus",
        "given": "Allegra"
      },
      {
        "family": "Kozen",
        "given": "Dexter"
      }
    ],
    "id": "angus2001kleene",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Cornell University",
    "title": "Kleene algebra with tests and program schematology",
    "type": "report"
  },
  {
    "author": [
      {
        "family": "Hoare",
        "given": "CAR Tony"
      },
      {
        "family": "Möller",
        "given": "Bernhard"
      },
      {
        "family": "Struth",
        "given": "Georg"
      },
      {
        "family": "Wehrman",
        "given": "Ian"
      }
    ],
    "container-title": "CONCUR",
    "id": "hoare2009concurrent",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "title": "Concurrent kleene algebra",
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "family": "Anderson",
        "given": "Carolyn Jane"
      },
      {
        "family": "Foster",
        "given": "Nate"
      },
      {
        "family": "Guha",
        "given": "Arjun"
      },
      {
        "family": "Jeannin",
        "given": "Jean-Baptiste"
      },
      {
        "family": "Kozen",
        "given": "Dexter"
      },
      {
        "family": "Schlesinger",
        "given": "Cole"
      },
      {
        "family": "Walker",
        "given": "David"
      }
    ],
    "container-title": "Principles of programming languages (POPL)",
    "id": "anderson2014netkat",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "title": "NetKAT: Semantic foundations for networks",
    "title-short": "NetKAT",
    "type": "paper-conference"
  },
  {
    "DOI": "https://doi.org/10.1006/inco.1994.1037",
    "ISSN": "0890-5401",
    "URL": "https://www.sciencedirect.com/science/article/pii/S0890540184710376",
    "abstract": "We give a finitary axiomatization of the algebra of regular events involving only equations and equational implications. Unlike Salomaa′s axiomatizations, the axiomatization given here is sound for all interpretations over Kleene algebras.",
    "author": [
      {
        "family": "Kozen",
        "given": "D."
      }
    ],
    "container-title": "Information and Computation",
    "id": "KOZEN1994366",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          1994
        ]
      ]
    },
    "page": "366-390",
    "title": "A completeness theorem for kleene algebras and the algebra of regular events",
    "type": "article-journal",
    "volume": "110"
  },
  {
    "author": [
      {
        "family": "Day",
        "given": "Brian John"
      }
    ],
    "genre": "PhD thesis",
    "id": "day1970construction",
    "issued": {
      "date-parts": [
        [
          1970
        ]
      ]
    },
    "publisher": "University of New South Wales PhD thesis",
    "title": "Construction of biclosed categories",
    "type": "thesis"
  },
  {
    "author": [
      {
        "family": "Kozen",
        "given": "Dexter"
      }
    ],
    "container-title": "Logic and Information Flow",
    "id": "kozen1994action",
    "issued": {
      "date-parts": [
        [
          1994
        ]
      ]
    },
    "title": "On action algebras",
    "type": "article-journal"
  },
  {
    "author": [
      {
        "family": "Kozen",
        "given": "Dexter"
      },
      {
        "family": "Patron",
        "given": "Maria-Cristina"
      }
    ],
    "container-title": "International conference on computational logic",
    "id": "kozen2000certification",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "page": "568-582",
    "publisher": "Springer",
    "title": "Certification of compiler optimizations using kleene algebra with tests",
    "type": "paper-conference"
  },
  {
    "DOI": "https://doi.org/10.1016/0304-3975(87)90045-4",
    "ISSN": "0304-3975",
    "URL": "https://www.sciencedirect.com/science/article/pii/0304397587900454",
    "abstract": "The familiar connective of negation is broken into two operations: linear negation which is the purely negative part of negation and the modality “of course” which has the meaning of a reaffirmation. Following this basic discovery, a completely new approach to the whole area between constructive logics and programmation is initiated.",
    "author": [
      {
        "family": "Girard",
        "given": "Jean-Yves"
      }
    ],
    "container-title": "Theoretical Computer Science",
    "id": "GIRARD19871",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "page": "1-101",
    "title": "Linear logic",
    "type": "article-journal",
    "volume": "50"
  },
  {
    "DOI": "10.1145/321479.321488",
    "ISSN": "0004-5411",
    "URL": "https://doi.org/10.1145/321479.321488",
    "abstract": "A new type of grammar for generating formal languages, called an indexed grammar, is presented. An indexed grammar is an extension of a context-free grammar, and the class of languages generated by indexed grammars has closure properties and decidability results similar to those for context-free languages. The class of languages generated by indexed grammars properly includes all context-free languages and is a proper subset of the class of context-sensitive languages. Several subclasses of indexed grammars generate interesting classes of languages.",
    "author": [
      {
        "family": "Aho",
        "given": "Alfred V."
      }
    ],
    "container-title": "J. ACM",
    "id": "AhoIndexed",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1968,
          10
        ]
      ]
    },
    "page": "647-671",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Indexed grammars—an extension of context-free grammars",
    "type": "article-journal",
    "volume": "15"
  },
  {
    "ISBN": "978-3-540-47285-8",
    "abstract": "We extend Kozen’s theory KA of Kleene Algebra to axiomatize parts of the equational theory of context-free languages, using a least fixed-point operator \\mu instead of Kleene’s iteration operator*.",
    "author": [
      {
        "family": "Leiß",
        "given": "Haas"
      }
    ],
    "container-title": "Computer science logic",
    "editor": [
      {
        "family": "Börger",
        "given": "Egon"
      },
      {
        "family": "Jäger",
        "given": "Gerhard"
      },
      {
        "family": "Kleine Büning",
        "given": "Hans"
      },
      {
        "family": "Richter",
        "given": "Michael M."
      }
    ],
    "id": "leiss",
    "issued": {
      "date-parts": [
        [
          1992
        ]
      ]
    },
    "page": "242-256",
    "publisher": "Springer Berlin Heidelberg",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Towards kleene algebra with recursion",
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "family": "Yoshinaga",
        "given": "Naoki"
      },
      {
        "family": "Miyao",
        "given": "Yusuke"
      },
      {
        "family": "Tsujii",
        "given": "Jun’ichi"
      }
    ],
    "container-title": "Proceedings of the sixth international workshop on tree adjoining grammar and related frameworks (TAG+ 6)",
    "id": "yoshinaga2002formal",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "page": "187-192",
    "title": "A formal proof of strong equivalence for a grammar conversion from LTAG to HPSG-style",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/BFb0018436",
    "ISBN": "978-3-540-53686-4 978-3-540-46982-7",
    "URL": "http://link.springer.com/10.1007/BFb0018436",
    "abstract": "In Floyd-Hoare logic, programs are dynamic while assertions are static (hold at states). In action logic the two notions become one, with programs viewed as on-the-ﬂy assertions whose truth is evaluated along intervals instead of at states. Action logic is an equational theory ACT conservatively extending the equational theory REG of regular expressions with operations preimplication a→b (had a then b) and postimplication b←a (b if-ever a). Unlike REG, ACT is ﬁnitely based, makes a∗ reﬂexive transitive closure, and has an equivalent Hilbert system. The crucial axiom is that of pure induction, (a→a)∗ = a→a.",
    "accessed": {
      "date-parts": [
        [
          2024,
          7,
          10
        ]
      ]
    },
    "author": [
      {
        "family": "Pratt",
        "given": "Vaughan"
      }
    ],
    "container-title": "Logics in AI",
    "editor": [
      {
        "family": "Siekmann",
        "given": "J."
      },
      {
        "family": "Goos",
        "given": "G."
      },
      {
        "family": "Hartmanis",
        "given": "J."
      },
      {
        "family": "Van Eijck",
        "given": "J."
      }
    ],
    "id": "prattActionLogicPure1991",
    "issued": {
      "date-parts": [
        [
          1991
        ]
      ]
    },
    "note": "Series Title: Lecture Notes in Computer Science",
    "page": "97-120",
    "publisher": "Springer Berlin Heidelberg",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Action logic and pure induction",
    "type": "chapter",
    "volume": "478"
  },
  {
    "URL": "http://arxiv.org/abs/1405.0033",
    "abstract": "A type theory is presented that combines (intuitionistic) linear types with type dependency, thus properly generalising both intuitionistic dependent type theory and full linear logic. A syntax and complete categorical semantics are developed, the latter in terms of (strict) indexed symmetric monoidal categories with comprehension. Various optional type formers are treated in a modular way. In particular, we will see that the historically much-debated multiplicative quantiﬁers and identity types arise naturally from categorical considerations. These new multiplicative connectives are further characterised by several identities relating them to the usual connectives from dependent type theory and linear logic. Finally, one important class of models, given by families with values in some symmetric monoidal category, is investigated in detail.",
    "accessed": {
      "date-parts": [
        [
          2024,
          7,
          10
        ]
      ]
    },
    "author": [
      {
        "family": "Vákár",
        "given": "Matthijs"
      }
    ],
    "id": "vakarSyntaxSemanticsLinear2015",
    "issued": {
      "date-parts": [
        [
          2015,
          1
        ]
      ]
    },
    "keyword": "Computer Science - Logic in Computer Science, Computer Science - Programming Languages, Mathematics - Category Theory",
    "note": "arXiv:1405.0033 [cs, math]",
    "publisher": "arXiv",
    "title": "Syntax and Semantics of Linear Dependent Types",
    "type": ""
  },
  {
    "URL": "https://arxiv.org/abs/2309.08673",
    "author": [
      {
        "family": "Fu",
        "given": "Qiancheng"
      },
      {
        "family": "Xi",
        "given": "Hongwei"
      }
    ],
    "id": "fu2023twolevellineardependenttype",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "title": "A two-level linear dependent type theory",
    "type": ""
  },
  {
    "ISBN": "978-3-540-27836-8",
    "abstract": "This paper studies the problem of matching sequences against regular expressions in order to produce structured values.",
    "author": [
      {
        "family": "Frisch",
        "given": "Alain"
      },
      {
        "family": "Cardelli",
        "given": "Luca"
      }
    ],
    "container-title": "Automata, languages and programming",
    "editor": [
      {
        "family": "Díaz",
        "given": "Josep"
      },
      {
        "family": "Karhumäki",
        "given": "Juhani"
      },
      {
        "family": "Lepistö",
        "given": "Arto"
      },
      {
        "family": "Sannella",
        "given": "Donald"
      }
    ],
    "id": "frischCardelli",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "page": "618-629",
    "publisher": "Springer Berlin Heidelberg",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Greedy regular expression matching",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2676724.2693177",
    "ISBN": "978-1-4503-3296-5",
    "URL": "https://dl.acm.org/doi/10.1145/2676724.2693177",
    "abstract": "Every context-free grammar can be transformed into an equivalent one in the Chomsky normal form by a sequence of four transformations. In this work on formalization of language theory, we prove formally in the Agda dependently typed programming language that each of these transformations is correct in the sense of making progress toward normality and preserving the language of the given grammar. Also, we show that the right sequence of these transformations leads to a grammar in the Chomsky normal form (since each next transformation preserves the normality properties established by the previous ones) that accepts the same language as the given grammar. As we work in a constructive setting, soundness and completeness proofs are functions converting between parse trees in the normalized and original grammars.",
    "accessed": {
      "date-parts": [
        [
          2024,
          5,
          13
        ]
      ]
    },
    "author": [
      {
        "family": "Firsov",
        "given": "Denis"
      },
      {
        "family": "Uustalu",
        "given": "Tarmo"
      }
    ],
    "container-title": "Proceedings of the 2015 Conference on Certified Programs and Proofs",
    "id": "firsovCertifiedNormalizationContextFree2015",
    "issued": {
      "date-parts": [
        [
          2015,
          1
        ]
      ]
    },
    "page": "167-174",
    "publisher": "ACM",
    "publisher-place": "Mumbai India",
    "title": "Certified Normalization of Context-Free Grammars",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/SPW53761.2021.00022",
    "author": [
      {
        "family": "Egolf",
        "given": "Derek"
      },
      {
        "family": "Lasser",
        "given": "Sam"
      },
      {
        "family": "Fisher",
        "given": "Kathleen"
      }
    ],
    "collection-number": "",
    "container-title": "2021 IEEE security and privacy workshops (SPW)",
    "id": "egolfVerbatim",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "Performance evaluation;Privacy;Conferences;Tools;Software systems;Generators;Security;lexical analysis;interactive theorem proving",
    "page": "92-100",
    "title": "Verbatim: A verified lexer generator",
    "title-short": "Verbatim",
    "type": "paper-conference",
    "volume": ""
  },
  {
    "DOI": "10.22152/programming-journal.org/2024/8/3",
    "ISSN": "2473-7321",
    "URL": "http://dx.doi.org/10.22152/programming-journal.org/2024/8/3",
    "author": [
      {
        "family": "Ouedraogo",
        "given": "Wendlasida"
      },
      {
        "family": "Scherer",
        "given": "Gabriel"
      },
      {
        "family": "Strassburger",
        "given": "Lutz"
      }
    ],
    "container-title": "The Art, Science, and Engineering of Programming",
    "id": "Ouedraogo_2023",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2023,
          6
        ]
      ]
    },
    "publisher": "Aspect-Oriented Software Association (AOSA)",
    "title": "Coqlex: Generating formally verified lexers",
    "title-short": "Coqlex",
    "type": "article-journal",
    "volume": "8"
  },
  {
    "DOI": "10.1145/1863543.1863585",
    "ISBN": "978-1-60558-794-3",
    "accessed": {
      "date-parts": [
        [
          2024,
          5,
          8
        ]
      ]
    },
    "author": [
      {
        "family": "Danielsson",
        "given": "Nils Anders"
      }
    ],
    "container-title": "Proceedings of the 15th ACM SIGPLAN international conference on Functional programming",
    "id": "danielssonTotalParserCombinators2010",
    "issued": {
      "date-parts": [
        [
          2010,
          9
        ]
      ]
    },
    "language": "en-US",
    "page": "285-296",
    "publisher": "ACM",
    "publisher-place": "Baltimore Maryland USA",
    "title": "Total parser combinators",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3453483.3454053",
    "ISBN": "978-1-4503-8391-2",
    "accessed": {
      "date-parts": [
        [
          2024,
          5,
          1
        ]
      ]
    },
    "author": [
      {
        "family": "Lasser",
        "given": "Sam"
      },
      {
        "family": "Casinghino",
        "given": "Chris"
      },
      {
        "family": "Fisher",
        "given": "Kathleen"
      },
      {
        "family": "Roux",
        "given": "Cody"
      }
    ],
    "container-title": "Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation",
    "id": "lasserCoStarVerifiedALL2021",
    "issued": {
      "date-parts": [
        [
          2021,
          6
        ]
      ]
    },
    "language": "en-US",
    "page": "420-434",
    "publisher": "ACM",
    "publisher-place": "Virtual Canada",
    "title": "CoStar: A verified ALL(*) parser",
    "title-short": "CoStar",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3473583",
    "ISSN": "2475-1421",
    "abstract": "Formal languages are usually defined in terms of set theory. Choosing type theory instead gives us languages as type-level predicates over strings. Applying a language to a string yields a type whose elements are language membership proofs describing how a string parses in the language. The usual building blocks of languages (including union, concatenation, and Kleene closure) have precise and compelling specifications uncomplicated by operational strategies and are easily generalized to a few general domain-transforming and codomain-transforming operations on predicates. A simple characterization of languages (and indeed functions from lists to any type) captures the essential idea behind language “differentiation” as used for recognizing languages, leading to a collection of lemmas about type-level predicates. These lemmas are the heart of two dual parsing implementations—using (inductive) regular expressions and (coinductive) tries—each containing the same code but in dual arrangements (with representation and primitive operations trading places). The regular expression version corresponds to symbolic differentiation, while the trie version corresponds to automatic differentiation. The relatively easy-to-prove properties of type-level languages transfer almost effortlessly to the decidable implementations. In particular, despite the inductive and coinductive nature of regular expressions and tries respectively, we need neither inductive nor coinductive/bisimulation arguments to prove algebraic properties.",
    "accessed": {
      "date-parts": [
        [
          2024,
          11,
          10
        ]
      ]
    },
    "author": [
      {
        "family": "Elliott",
        "given": "Conal"
      }
    ],
    "container-title": "Proceedings of the ACM on Programming Languages",
    "id": "elliottSymbolicAutomaticDifferentiation2021",
    "issue": "ICFP",
    "issued": {
      "date-parts": [
        [
          2021,
          8
        ]
      ]
    },
    "language": "en-US",
    "page": "1-18",
    "title": "Symbolic and automatic differentiation of languages",
    "type": "article-journal",
    "volume": "5"
  },
  {
    "DOI": "10.1145/3385412.3385992",
    "ISBN": "9781450376136",
    "URL": "https://doi.org/10.1145/3385412.3385992",
    "abstract": "In this paper, we present an efficient, functional, and formally verified parsing algorithm for LL(1) context-free expressions based on the concept of derivatives of formal languages. Parsing with derivatives is an elegant parsing technique, which, in the general case, suffers from cubic worst-case time complexity and slow performance in practice. We specialise the parsing with derivatives algorithm to LL(1) context-free expressions, where alternatives can be chosen given a single token of lookahead. We formalise the notion of LL(1) expressions and show how to efficiently check the LL(1) property. Next, we present a novel linear-time parsing with derivatives algorithm for LL(1) expressions operating on a zipper-inspired data structure. We prove the algorithm correct in Coq and present an implementation as a part of Scallion, a parser combinators framework in Scala with enumeration and pretty printing capabilities.",
    "author": [
      {
        "family": "Edelmann",
        "given": "Romain"
      },
      {
        "family": "Hamza",
        "given": "Jad"
      },
      {
        "family": "Kunčak",
        "given": "Viktor"
      }
    ],
    "collection-title": "PLDI 2020",
    "container-title": "Proceedings of the 41st ACM SIGPLAN conference on programming language design and implementation",
    "id": "EdelmannZippy2020",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "Zipper, Parsing, LL(1), Formal proof, Derivatives",
    "page": "1036-1051",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Zippy LL(1) parsing with derivatives",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3341691",
    "URL": "https://doi.org/10.1145/3341691",
    "abstract": "Proof assistants based on dependent type theory provide expressive languages for both programming and proving within the same system. However, all of the major implementations lack powerful extensionality principles for reasoning about equality, such as function and propositional extensionality. These principles are typically added axiomatically which disrupts the constructive properties of these systems. Cubical type theory provides a solution by giving computational meaning to Homotopy Type Theory and Univalent Foundations, in particular to the univalence axiom and higher inductive types. This paper describes an extension of the dependently typed functional programming language Agda with cubical primitives, making it into a full-blown proof assistant with native support for univalence and a general schema of higher inductive types. These new primitives make function and propositional extensionality as well as quotient types directly definable with computational content. Additionally, thanks also to copatterns, bisimilarity is equivalent to equality for coinductive types. This extends Agda with support for a wide range of extensionality principles, without sacrificing type checking and constructivity.",
    "author": [
      {
        "family": "Vezzosi",
        "given": "Andrea"
      },
      {
        "family": "Mörtberg",
        "given": "Anders"
      },
      {
        "family": "Abel",
        "given": "Andreas"
      }
    ],
    "container-title": "Proc. ACM Program. Lang.",
    "id": "VezzosiMortbergAbel2019",
    "issue": "ICFP",
    "issued": {
      "date-parts": [
        [
          2019,
          7
        ]
      ]
    },
    "keyword": "Univalence, Cubical Type Theory, Higher Inductive Types, Dependent Pattern Matching",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Cubical agda: A dependently typed programming language with univalence and higher inductive types",
    "title-short": "Cubical agda",
    "type": "article-journal",
    "volume": "3"
  },
  {
    "DOI": "10.1080/00029890.1958.11989160",
    "URL": "https://doi.org/10.1080/00029890.1958.11989160",
    "author": [
      {
        "family": "Lambek",
        "given": "Joachim"
      }
    ],
    "container-title": "The American Mathematical Monthly",
    "id": "lambek58",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          1958
        ]
      ]
    },
    "page": "154-170",
    "publisher": "Taylor & Francis",
    "title": "The mathematics of sentence structure",
    "type": "article-journal",
    "volume": "65"
  },
  {
    "author": [
      {
        "family": "Hofmann",
        "given": "Martin"
      }
    ],
    "collection-title": "Publications of the newton institute",
    "container-title": "Semantics and logics of computation",
    "id": "Hofmann_1997",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "page": "79-130",
    "publisher": "Cambridge University Press",
    "title": "Syntax and semantics of dependent types",
    "type": "chapter"
  },
  {
    "DOI": "10.1090/conm/092/1003210",
    "ISBN": "0-8218-5100-4",
    "URL": "https://doi.org/10.1090/conm/092/1003210",
    "author": [
      {
        "family": "Seely",
        "given": "R. A. G."
      }
    ],
    "collection-title": "Contemp. math.",
    "container-title": "Categories in computer science and logic (Boulder, CO, 1987)",
    "id": "seely89",
    "issued": {
      "date-parts": [
        [
          1989
        ]
      ]
    },
    "page": "371-382",
    "publisher": "Amer. Math. Soc., Providence, RI",
    "title": "Linear logic, *-autonomous categories and cofree coalgebras",
    "type": "chapter",
    "volume": "92"
  },
  {
    "DOI": "10.46298/lmcs-17(3:11)2021",
    "URL": "https://lmcs.episciences.org/7713",
    "author": [
      {
        "family": "Gratzer",
        "given": "Daniel"
      },
      {
        "family": "Kavvos",
        "given": "G. A."
      },
      {
        "family": "Nuyts",
        "given": "Andreas"
      },
      {
        "family": "Birkedal",
        "given": "Lars"
      }
    ],
    "container-title": "Logical Methods in Computer Science",
    "id": "lmcs:7713",
    "issued": {
      "date-parts": [
        [
          2021,
          7
        ]
      ]
    },
    "keyword": "Computer Science - Logic in Computer Science",
    "title": "Multimodal Dependent Type Theory",
    "type": "article-journal",
    "volume": "Volume 17, Issue 3"
  },
  {
    "DOI": "https://doi.org/10.1016/0304-3975(87)90045-4",
    "ISSN": "0304-3975",
    "URL": "https://www.sciencedirect.com/science/article/pii/0304397587900454",
    "abstract": "The familiar connective of negation is broken into two operations: linear negation which is the purely negative part of negation and the modality “of course” which has the meaning of a reaffirmation. Following this basic discovery, a completely new approach to the whole area between constructive logics and programmation is initiated.",
    "author": [
      {
        "family": "Girard",
        "given": "Jean-Yves"
      }
    ],
    "container-title": "Theoretical Computer Science",
    "id": "girard_linear_1987",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "page": "1-101",
    "title": "Linear logic",
    "type": "article-journal",
    "volume": "50"
  },
  {
    "author": [
      {
        "family": "Univalent Foundations Program",
        "given": "The"
      }
    ],
    "id": "hottbook",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "publisher": "https://homotopytypetheory.org/book",
    "publisher-place": "Institute for Advanced Study",
    "title": "Homotopy type theory: Univalent foundations of mathematics",
    "title-short": "Homotopy type theory",
    "type": "book"
  },
  {
    "DOI": "10.4230/LIPIcs.TYPES.2021.10",
    "URL": "https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.TYPES.2021.10",
    "abstract": "We investigate containers and polynomial functors in Quantitative Type Theory, and give initial algebra semantics of inductive data types in the presence of linearity. We show that reasoning by induction is supported, and equivalent to initiality, also in the linear setting.",
    "accessed": {
      "date-parts": [
        [
          2024,
          11,
          13
        ]
      ]
    },
    "author": [
      {
        "family": "Nakov",
        "given": "Georgi"
      },
      {
        "family": "Nordvall Forsberg",
        "given": "Fredrik"
      }
    ],
    "container-title": "27th International Conference on Types for Proofs and Programs (TYPES 2021)",
    "id": "nakov_quantitative_2022",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "page": "10:1-10:22",
    "publisher": "Schloss Dagstuhl – Leibniz-Zentrum für Informatik",
    "title": "Quantitative Polynomial Functors",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2951913.2951943",
    "ISBN": "978-1-4503-4219-3",
    "URL": "https://dl.acm.org/doi/10.1145/2951913.2951943",
    "abstract": "The development of concurrent separation logic (CSL) has sparked a long line of work on modular verification of sophisticated concurrent programs. Two of the most important features supported by several existing extensions to CSL are higher-order quantification and custom ghost state. However, none of the logics that support both of these features reap the full potential of their combination. In particular, none of them provide general support for a feature we dub \"higher-order ghost state\": the ability to store arbitrary higher-order separation-logic predicates in ghost variables. In this paper, we propose higher-order ghost state as a interesting and useful extension to CSL, which we formalize in the framework of Jung et al.’s recently developed Iris logic. To justify its soundness, we develop a novel algebraic structure called CMRAs (\"cameras\"), which can be thought of as \"step-indexed partial commutative monoids\". Finally, we show that Iris proofs utilizing higher-order ghost state can be effectively formalized in Coq, and discuss the challenges we faced in formalizing them.",
    "accessed": {
      "date-parts": [
        [
          2024,
          11,
          14
        ]
      ]
    },
    "author": [
      {
        "family": "Jung",
        "given": "Ralf"
      },
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Birkedal",
        "given": "Lars"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "collection-title": "ICFP 2016",
    "container-title": "Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming",
    "id": "jung_higher-order_2016",
    "issued": {
      "date-parts": [
        [
          2016,
          9
        ]
      ]
    },
    "page": "256-269",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Higher-order ghost state",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/BFb0023771",
    "ISBN": "978-3-540-47285-8",
    "abstract": "We extend Kozen’s theory KA of Kleene Algebra to axiomatize parts of the equational theory of context-free languages, using a least fixed-point operator μ instead of Kleene’s iteration operator*.",
    "author": [
      {
        "family": "Leiß",
        "given": "Haas"
      }
    ],
    "container-title": "Computer Science Logic",
    "editor": [
      {
        "family": "Börger",
        "given": "Egon"
      },
      {
        "family": "Jäger",
        "given": "Gerhard"
      },
      {
        "family": "Kleine Büning",
        "given": "Hans"
      },
      {
        "family": "Richter",
        "given": "Michael M."
      }
    ],
    "id": "leis_towards_1992",
    "issued": {
      "date-parts": [
        [
          1992
        ]
      ]
    },
    "keyword": "Continuous Model, Equational Theory, Finite Automaton, Regular Expression, Regular Language",
    "page": "242-256",
    "publisher": "Springer",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Towards Kleene Algebra with recursion",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/S0019-9958(70)90446-8",
    "ISSN": "0019-9958",
    "URL": "https://www.sciencedirect.com/science/article/pii/S0019995870904468",
    "abstract": "The class of context-free grammars that can be deterministically parsed in a top down manner with a fixed amount of look-ahead is investigated. These grammars, called LL(k) grammars where k is the amount of look-ahead are defined and a procedure is given for determining if a context-free grammar is LL(k) for a given value of k. A procedure is given for eliminating the ε-rules from an LL(k) grammar at the cost of increasing k by 1. There exist cases in which this increase is inevitable. A procedure is given for obtaining a deterministic push-down machine to recognize a given LL(k) grammar and it is shown that the equivalence problem is decidable for LL(k) grammars. Additional properties are also given.",
    "accessed": {
      "date-parts": [
        [
          2024,
          11,
          14
        ]
      ]
    },
    "author": [
      {
        "family": "Rosenkrantz",
        "given": "D. J."
      },
      {
        "family": "Stearns",
        "given": "R. E."
      }
    ],
    "container-title": "Information and Control",
    "id": "rosenkrantz_properties_1970",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          1970,
          10
        ]
      ]
    },
    "page": "226-256",
    "title": "Properties of deterministic top-down grammars",
    "type": "article-journal",
    "volume": "17"
  },
  {
    "DOI": "10.1007/978-3-540-24849-1_14",
    "ISBN": "978-3-540-24849-1",
    "abstract": "We set out to study the consequences of the assumption of types of wellfounded trees in dependent type theories. We do so by investigating the categorical notion of wellfounded tree introduced in [16]. Our main result shows that wellfounded trees allow us to define initial algebras for a wide class of endofunctors on locally cartesian closed categories.",
    "author": [
      {
        "family": "Gambino",
        "given": "Nicola"
      },
      {
        "family": "Hyland",
        "given": "Martin"
      }
    ],
    "container-title": "Types for Proofs and Programs",
    "editor": [
      {
        "family": "Berardi",
        "given": "Stefano"
      },
      {
        "family": "Coppo",
        "given": "Mario"
      },
      {
        "family": "Damiani",
        "given": "Ferruccio"
      }
    ],
    "id": "gambino_wellfounded_2004",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "keyword": "Forgetful Functor, Left Adjoint, Monoidal Category, Natural Transformation, Type Theory",
    "page": "210-225",
    "publisher": "Springer",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Wellfounded Trees and Dependent Polynomial Functors",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1017/S095679681500009X",
    "ISSN": "0956-7968, 1469-7653",
    "URL": "https://www.cambridge.org/core/journals/journal-of-functional-programming/article/indexed-containers/FB9C7DC88A65E7529D39554379D9765F",
    "abstract": "We show that the syntactically rich notion of strictly positive families can be reduced to a core type theory with a fixed number of type constructors exploiting the novel notion of indexed containers. As a result, we show indexed containers provide normal forms for strictly positive families in much the same way that containers provide normal forms for strictly positive types. Interestingly, this step from containers to indexed containers is achieved without having to extend the core type theory. Most of the construction presented here has been formalized using the Agda system.",
    "accessed": {
      "date-parts": [
        [
          2024,
          11,
          14
        ]
      ]
    },
    "author": [
      {
        "family": "Altenkirch",
        "given": "Thorsten"
      },
      {
        "family": "Ghani",
        "given": "Neil"
      },
      {
        "family": "Hancock",
        "given": "Peter"
      },
      {
        "family": "Mcbride",
        "given": "Conor"
      },
      {
        "family": "Morris",
        "given": "Peter"
      }
    ],
    "container-title": "Journal of Functional Programming",
    "id": "altenkirch_indexed_2015",
    "issued": {
      "date-parts": [
        [
          2015,
          1
        ]
      ]
    },
    "page": "e5",
    "title": "Indexed containers",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "DOI": "10.1109/LICS.2015.11",
    "author": [
      {
        "family": "O’Hearn",
        "given": "Peter"
      }
    ],
    "collection-number": "",
    "container-title": "2015 30th annual ACM/IEEE symposium on logic in computer science",
    "id": "7174865",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "Semantics;Facebook;Computer science;Mathematical model;Cognition;Syntactics;Shape",
    "page": "17-20",
    "title": "From categorical logic to facebook engineering",
    "type": "paper-conference",
    "volume": ""
  },
  {
    "DOI": "10.1109/LICS.2002.1029817",
    "URL": "https://ieeexplore.ieee.org/document/1029817",
    "abstract": "In joint work with Peter O’Hearn and others, based on early ideas of Burstall, we have developed an extension of Hoare logic that permits reasoning about low-level imperative programs that use shared mutable data structure. The simple imperative programming language is extended with commands (not expressions) for accessing and modifying shared structures, and for explicit allocation and deallocation of storage. Assertions are extended by introducing a \"separating conjunction\" that asserts that its subformulas hold for disjoint parts of the heap, and a closely related \"separating implication\". Coupled with the inductive definition of predicates on abstract data structures, this extension permits the concise and flexible description of structures with controlled sharing. In this paper, we survey the current development of this program logic, including extensions that permit unrestricted address arithmetic, dynamically allocated arrays, and recursive procedures. We also discuss promising future directions.",
    "accessed": {
      "date-parts": [
        [
          2024,
          11,
          14
        ]
      ]
    },
    "author": [
      {
        "family": "Reynolds",
        "given": "J. C."
      }
    ],
    "container-title": "Proceedings 17th Annual IEEE Symposium on Logic in Computer Science",
    "id": "reynolds_separation_2002",
    "issued": {
      "date-parts": [
        [
          2002,
          7
        ]
      ]
    },
    "keyword": "Arithmetic, Artificial intelligence, Bibliographies, Computer languages, Computer science, Data structures, Logic arrays, Logic programming, Programmable logic arrays, Reflection",
    "note": "ISSN: 1043-6871",
    "page": "55-74",
    "title": "Separation logic: A logic for shared mutable data structures",
    "title-short": "Separation logic",
    "type": "paper-conference"
  },
  {
    "author": [
      {
        "family": "Montague",
        "given": "Richard"
      }
    ],
    "id": "Montague1974-MONFPS",
    "issued": {
      "date-parts": [
        [
          1974
        ]
      ]
    },
    "publisher": "Yale University Press",
    "publisher-place": "New Haven,",
    "title": "Formal philosophy: Selected papers of richard montague",
    "title-short": "Formal philosophy",
    "type": "book"
  },
  {
    "DOI": "10.1007/978-94-017-3598-8_12",
    "ISBN": "978-90-481-6414-1 978-94-017-3598-8",
    "URL": "http://link.springer.com/10.1007/978-94-017-3598-8_12",
    "accessed": {
      "date-parts": [
        [
          2024,
          8,
          7
        ]
      ]
    },
    "author": [
      {
        "family": "Buszkowski",
        "given": "W."
      }
    ],
    "container-title": "Trends in Logic",
    "editor": [
      {
        "family": "Wójcicki",
        "given": "Ryszard"
      },
      {
        "family": "Mundici",
        "given": "Daniele"
      },
      {
        "family": "Orłowska",
        "given": "Ewa"
      },
      {
        "family": "Priest",
        "given": "Graham"
      },
      {
        "family": "Segerberg",
        "given": "Krister"
      },
      {
        "family": "Urquhart",
        "given": "Alasdair"
      },
      {
        "family": "Wansing",
        "given": "Heinrich"
      },
      {
        "family": "Hendricks",
        "given": "Vincent F."
      },
      {
        "family": "Malinowski",
        "given": "Jacek"
      }
    ],
    "id": "buszkowskiTypeLogicsGrammar2003",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "note": "Series Title: Trends in Logic",
    "page": "337-382",
    "publisher": "Springer Netherlands",
    "publisher-place": "Dordrecht",
    "title": "Type Logics in Grammar",
    "type": "chapter",
    "volume": "21"
  },
  {
    "ISBN": "1575866269",
    "abstract": "Grammatical Framework is a programming language designed for writing grammars, which has the capability of addressing several languages in parallel. This thorough introduction demonstrates how to write grammars in Grammatical Framework and use them in applications such as tourist phrasebooks, spoken dialogue systems, and natural language interfaces. The examples and exercises presented here address several languages, and the readers are shown how to look at their own languages from the computational perspective.",
    "author": [
      {
        "family": "Ranta",
        "given": "Aarne"
      }
    ],
    "id": "ranta-2011",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "publisher": "Center for the Study of Language; Information/SRI",
    "title": "Grammatical framework: Programming with multilingual grammars",
    "title-short": "Grammatical framework",
    "type": "book"
  },
  {
    "DOI": "10.29007/qrqp",
    "author": [
      {
        "family": "Luo",
        "given": "Zhaohui"
      }
    ],
    "id": "luo",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "publisher": "EasyChair Preprint 421",
    "title": "Substructural calculi with dependent types",
    "type": "pamphlet"
  },
  {
    "DOI": "10.1007/978-94-015-6878-4_11",
    "ISBN": "978-94-015-6878-4",
    "URL": "https://doi.org/10.1007/978-94-015-6878-4_11",
    "abstract": "Having been under the impression that categorial grammars in general and the so-called syntactic calculus in particular had been swept away by the tide of transformational grammar, I was very surprised to learn of the recent revival of interest in these matters, as, for example, by Buszkowski in Poland and by van Benthem in the Netherlands. Stimulated by the renewed activity in this area, I decided to take another look at it, and in particular, to explore the categorical connection, which had been at the back of my mind all along.",
    "author": [
      {
        "family": "Lambek",
        "given": "J."
      }
    ],
    "container-title": "Categorial grammars and natural language structures",
    "editor": [
      {
        "family": "Oehrle",
        "given": "Richard T."
      },
      {
        "family": "Bach",
        "given": "Emmon"
      },
      {
        "family": "Wheeler",
        "given": "Deirdre"
      }
    ],
    "id": "lambek1988categorial",
    "issued": {
      "date-parts": [
        [
          1988
        ]
      ]
    },
    "page": "297-317",
    "publisher": "Springer Netherlands",
    "publisher-place": "Dordrecht",
    "title": "Categorial and categorical grammars",
    "type": "chapter"
  },
  {
    "DOI": "10.1007/978-981-97-2300-3_2",
    "ISBN": "978-981-97-2299-0",
    "URL": "https://doi.org/10.1007/978-981-97-2300-3_2",
    "abstract": "Abstract categorial grammars (ACGs) is an expressive grammatical framework whose formal properties have been extensively studied. While it can provide its own account, as a grammar, of linguistic phenomena, it is known to encode several grammatical formalisms, including context-free grammars, but also mildly context-sensitive formalisms such as tree-adjoining grammars or m-linear context-free rewriting systems for which parsing is polynomial. The ACG toolkit we present provides a compiler, acgc, that checks and turns ACGs into representations that are suitable for testing and parsing, used in the acg interpreter. We illustrate these functionalities and discuss implementation features, in particular the Datalog reduction on which parsing is based, and the magic set rewriting techniques that can further be applied.",
    "author": [
      {
        "family": "Guillaume",
        "given": "Maxime"
      },
      {
        "family": "Pogodalla",
        "given": "Sylvain"
      },
      {
        "family": "Tourneur",
        "given": "Vincent"
      }
    ],
    "container-title": "Functional and logic programming: 17th international symposium, FLOPS 2024, kumamoto, japan, may 15–17, 2024, proceedings",
    "id": "Guillaume2024",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "Abstract Categorial Grammars, Natural Language Processing, OCaml, Datalog",
    "page": "13-30",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "ACGtk: A toolkit for developing and running abstract categorial grammars",
    "title-short": "ACGtk",
    "type": "paper-conference"
  }
]
