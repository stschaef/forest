[{"URL": "http://arxiv.org/abs/2104.05997", "abstract": "Although Convolutional Neural Networks (CNNs) are widely used, their translation invariance (ability to deal with translated inputs) is still subject to some controversy. We explore this question using translation-sensitivity maps to quantify how sensitive a standard CNN is to a translated input. We propose the use of Cosine Similarity as sensitivity metric over Euclidean Distance, and discuss the importance of restricting the dimensionality of either of these metrics when comparing architectures. Our main focus is to investigate the effect of different architectural components of a standard CNN on that network\u2019s sensitivity to translation. By varying convolutional kernel sizes and amounts of zero padding, we control the size of the feature maps produced, allowing us to quantify the extent to which these elements influence translation invariance. We also measure translation invariance at different locations within the CNN to determine the extent to which convolutional and fully connected layers, respectively, contribute to the translation invariance of a CNN as a whole. Our analysis indicates that both convolutional kernel size and feature map size have a systematic influence on translation invariance. We also see that convolutional layers contribute less than expected to translation invariance, when not specifically forced to do so.", "accessed": {"date-parts": [[2024, 1, 15]]}, "author": [{"family": "Myburgh", "given": "Johannes C."}, {"family": "Mouton", "given": "Coenraad"}, {"family": "Davel", "given": "Marelie H."}], "id": "myburghTrackingTranslationInvariance2021", "issued": {"date-parts": [[2021, 4, 19]]}, "keyword": "Computer Science - Machine Learning", "status": "pre-published", "title": "Tracking translation invariance in CNNs", "type": "article-journal", "original_bibtex": "@article{myburghTrackingTranslationInvariance2021,\n title = {Tracking Translation Invariance in {{CNNs}}},\n author = {Myburgh, Johannes C. and Mouton, Coenraad and Davel, Marelie H.},\n date = {2021-04-19},\n url = {http://arxiv.org/abs/2104.05997},\n urldate = {2024-01-15},\n file = {/Users/stevenschaefer/Zotero/storage/5LHTBWEI/Myburgh et al. - 2021 - Tracking translation invariance in CNNs.pdf;/Users/stevenschaefer/Zotero/storage/YN4MZRDR/2104.html},\n keywords = {Computer Science - Machine Learning},\n pubstate = {prepublished},\n abstract = {Although Convolutional Neural Networks (CNNs) are widely used, their translation invariance (ability to deal with translated inputs) is still subject to some controversy. We explore this question using translation-sensitivity maps to quantify how sensitive a standard CNN is to a translated input. We propose the use of Cosine Similarity as sensitivity metric over Euclidean Distance, and discuss the importance of restricting the dimensionality of either of these metrics when comparing architectures. Our main focus is to investigate the effect of different architectural components of a standard CNN on that network's sensitivity to translation. By varying convolutional kernel sizes and amounts of zero padding, we control the size of the feature maps produced, allowing us to quantify the extent to which these elements influence translation invariance. We also measure translation invariance at different locations within the CNN to determine the extent to which convolutional and fully connected layers, respectively, contribute to the translation invariance of a CNN as a whole. Our analysis indicates that both convolutional kernel size and feature map size have a systematic influence on translation invariance. We also see that convolutional layers contribute less than expected to translation invariance, when not specifically forced to do so.},\n eprintclass = {cs},\n eprinttype = {arXiv},\n eprint = {2104.05997}\n}\n"}]